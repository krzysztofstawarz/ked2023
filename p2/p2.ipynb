{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254c4312-afb4-4632-a341-5da88ee00ecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Eksploracja danych**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e432c6d-17aa-43ae-816a-b8b32a307afa",
   "metadata": {},
   "source": [
    "## **Projek 2: Klasyfikacja przy użyciu KNN**  \n",
    "## Krzysztof Stawarz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228ca61-68e1-4904-b37a-91db825e273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GlassData = cell2mat(struct2cell(load('ed-p02.mat', 'GlassData')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e643b2-e9b5-4364-bd8d-d8725a3c5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GlassClasses = cell2mat(struct2cell(load('ed-p02.mat', 'GlassClasses')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f67840-9e86-4a4d-b44c-371b0372cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = cell2mat(struct2cell(load('ed-p02.mat', 'TestData')));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58ed5c-2d9f-4666-b82e-9925a318ed96",
   "metadata": {},
   "source": [
    "### **Rozwiązanie typu: od zera**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b010ee-59b0-4192-8e51-96314c30c551",
   "metadata": {},
   "source": [
    "*Piszemy wszystko od początku (pomimo, że ktoś mądry kiedyś za nas już to napisał, ale to nieistotne!!!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db329b1-49a4-4fc3-a8a1-35f3a4767f7f",
   "metadata": {},
   "source": [
    "#### **Krok 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa89064-54b9-455a-b0f3-57ac9865ecc5",
   "metadata": {},
   "source": [
    "*Dzielimy obecny dataset na zbiór do nauki ( `train_data` ) i przetestowania rezutlatów ( `test_data` ).  \n",
    "Robimy to też z labelami - `train_labels` i `test_labels`.*  \n",
    "  \n",
    "*Ja preferuję podział 3:1 dla testowego, ale można sobie wybrać dowolny. Raczej nie przekracza się 50%/50%.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94baab2-1984-4c59-91b9-009dbebff9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = .75;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfff50-3ba2-454b-92b0-c9cec4e664ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%  wektor decyzyjny z losowymi wartosciami, to dzieki niemu decydujemy czy wiersz dopisac do sekcji treningowej czy testowej\n",
    "decision_vect = rand(size(GlassData, 1), 1);\n",
    "\n",
    "train_data = GlassData(decision_vect <= train_frac, :);\n",
    "train_labels = GlassClasses(decision_vect <= train_frac, :);\n",
    "\n",
    "test_data = GlassData(decision_vect > train_frac, :);\n",
    "test_labels = GlassClasses(decision_vect > train_frac, :);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b27bc-3948-4a16-a389-297cb90c1171",
   "metadata": {},
   "source": [
    "#### **Krok 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5892939-ed00-4427-bd58-a46efa710a67",
   "metadata": {},
   "source": [
    "*Wprowadzamy kilka zmiennych służących nam za skróty, żeby nie pisać kilka razy tego samego*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ee143-b5e4-4aba-b24e-3df776f1b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows_n = size(train_data, 1)\n",
    "train_cols_n = size(train_data, 2)\n",
    "\n",
    "test_rows_n = size(test_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef6387-0724-4ab7-a19b-4c3425ba5288",
   "metadata": {},
   "source": [
    "#### **Krok 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b33b9-7d4e-497f-b071-ef051d691898",
   "metadata": {},
   "source": [
    "*Zaczynamy od rzeczy trywialnych. Napiszmy pętlę `for`, zliczającą odległość (w metryce taksówkowej) parametrów z pierwszego wiersza zbioru testowego i treningowego:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8fe0b-d975-45ac-a5ac-7f29af53a89f",
   "metadata": {},
   "source": [
    "$d(x, y) = \\sum\\limits_{i=0}^{n}|x_1 - y_1| + |x_2 - y_2| + ... + |x_n - y_n|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc827aaf-1788-46a4-8aa1-fa7e63d49a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 0;\n",
    "for i = 1:train_cols_n\n",
    "    distance = distance + abs(train_data(1, i) - test_data(1, i));\n",
    "end\n",
    "\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f118b8ed-0b13-48e1-beaa-30e571da4b0b",
   "metadata": {},
   "source": [
    "#### **Krok 4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0257100-d75a-4ce7-8b1d-24a96afdb19d",
   "metadata": {},
   "source": [
    "*Potrafiąc policzyć dystans jednego wiersza testowego do jednego treningowego, możemy teraz policzyć dystanse jednego wiersza testowego do **każego** wiersza treningowego (zapisując wyniki z zmiennej `distances`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5a7b5-3753-400b-a019-03c578e72a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [];\n",
    "\n",
    "    for j=1:train_rows_n\n",
    "    \n",
    "        distance = 0;\n",
    "        for i = 1:train_cols_n\n",
    "            distance = distance + abs(train_data(j, i) - test_data(1, i));\n",
    "        end\n",
    "        \n",
    "        distances = [distances, distance];\n",
    "\n",
    "    end\n",
    "\n",
    "% dystanse to wektor poziomy, stransponuje go i skrócę do pierwszych 5-ciu wyników w celu wyświetlenia\n",
    "% aby nie zajmował niepotrzebnie miejsca (bedzie mial +/- 126 wierszy)\n",
    "distances(:, 1:5)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00b5c6-9900-4bc8-995c-fe1b2052f4a8",
   "metadata": {},
   "source": [
    "*Musimy się na tym etapie stety bądź nie trochę ubrudzić.*  \n",
    "1. *Będziemy chcieli zmapować dystanse do odpowiednich wierszy jako pary {dystans: label_wiersza}. Użyjemy do tego celu słownika, a właściwie funkcji `sorted_dict`, napisanej w osobnym pliku w tym folderze. Funkcja ta zwraca słownik takich par, posortowany rosnąco według kluczy (dystansów), co będzie przydatne w dalszym etapie rozwiązania*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9ca77-b2dc-4386-8dea-9025918b18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sorted_dict(distances', train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb37ee3-e1ef-4100-b5a8-2b5bb71ccc36",
   "metadata": {},
   "source": [
    "*Posiadając taki słownik, możemy użyć już algorytmu __KNN__ - możemy sklasyfikować obserwację do jednej z sześciu klas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2bdca-a31d-47d5-9b54-7a1352838c9c",
   "metadata": {},
   "source": [
    "2. *Aplikujemy algorytm __KNN__, co oznacza, że będziemy patrzeć na __k__ najbliższych sąsiadów, czyli __k__ najmniejszych dystansów, oraz na labele wierszy, do których się odnoszą (stąd użycie słownika, chcemy śledzić obydwie wartości naraz i ich nie pogubić)*  \n",
    "*Do wyznaczania współczynnika __k__ przejdziemy w ostatnim kroku, na razie przyjmijmy __k=10__ na potrzeby prezentacji pomysłu.*  \n",
    "*Funkcja `sorted_dict` ma zaimplementowane użycie trzeciego argumentu jako współczynnika __k__ - uzystany w ten sposób słownik będzie posiadał __k__ pierwszych par.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c886a2-cb47-4f58-a331-d0fc881cb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10;\n",
    "\n",
    "d = sorted_dict(distances', train_labels, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7b84e-c898-4e83-a28a-361012223f85",
   "metadata": {},
   "source": [
    "3. *Gdy uzyskamy słownik z __k__ najmniejszymi dystansami, musimy znaleźć najczęściej występujący w nim label - to będzie nasza __predykacja, strzał, przewidywanie lub klasyfikacja__, jak zwał tak zwał*  \n",
    "*Do znaleziena najczęściej występującej wartości (labelu) w słowniku służy funkcja `most_frequent_value`, napisana w osobnym pliku w tym folderze.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47951752-f2dd-484a-adde-2999e88a6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = most_frequent_value(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9797fd3-f6b7-435c-a38e-f1d5e01676ad",
   "metadata": {},
   "source": [
    "*Powyższa odpowiedź oznacza, że nasz zaimplementowany algorytm na podstawie danych jakie otrzymał (pamiętajmy __k__ = 10) uważa, że pierwszy wiersz w zbiorze testowym powinien należeć do klasy nr 1.*  \n",
    "*Z racji, że zbiór testowy wyodrębniliśmy z naszego pierwotnego datasetu, możemy sprawdzić dokładność tej predykcji w niezwykle binarny sposób - przyrównać predykcję algorytmu do faktycznie przydzielonej do obserwacji klasy:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93c91c-f1fd-42b7-a111-232fc084fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label == test_labels(1, :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61530852-ee39-4381-8f42-abad704eb3af",
   "metadata": {},
   "source": [
    "*Hurra! Udało nam się napisać algorytm KNN dla jednego wiersza!*  \n",
    "  \n",
    "#### __Krok 5.__  \n",
    "  \n",
    "\n",
    "*Teraz zamknijmy go w pętli, aby przeszedł po każdym wierszu ze zbioru do testu. W dodatku będziemy mogli w ten sposob policzyć jego dokładność, śledząc stosunek udanych predykcji do wszystkich obrotów pętli `for`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2edd86-f5aa-4b85-a68e-27d104ae8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_guesses = 0;\n",
    "correct_guesses = 0;\n",
    "\n",
    "for test_row=1:test_rows_n   \n",
    "    all_guesses = all_guesses + 1;\n",
    "    \n",
    "    distances = [];\n",
    "\n",
    "    for j=1:train_rows_n\n",
    "\n",
    "        distance = 0;\n",
    "        for i = 1:train_cols_n\n",
    "            distance = distance + abs(train_data(j, i) - test_data(test_row, i));\n",
    "        end\n",
    "\n",
    "        distances = [distances, distance];\n",
    "\n",
    "    end\n",
    "    \n",
    "     d = sorted_dict(distances', train_labels, k);\n",
    "     predicted_label = most_frequent_value(d);\n",
    "\n",
    "     if predicted_label == test_labels(test_row, :)\n",
    "        correct_guesses = correct_guesses + 1;\n",
    "     end\n",
    "    \n",
    "end\n",
    "\n",
    "accuracy = correct_guesses / all_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5392a2-a21d-485a-9ffb-1a191b33545e",
   "metadata": {},
   "source": [
    "*Taka jest dokładność naszego algorytmu przy takim losowym podziale na testówke i treningówę i, co ważne, przy parametrze __k__=10*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64c22c-e6e7-45e1-b1a6-0ac09b78b846",
   "metadata": {},
   "source": [
    "#### __Krok 6.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75b86e-882d-4621-bf49-00b8fbcf1f1d",
   "metadata": {},
   "source": [
    "*Jak znajdziemy najbardziej optymalny współczynnik __k__? My użyjemy algorytmu nazywającego się __brute force__. Przeitereujemy po wszystkich możliwych wartościach __k__ i znajdziemy ten z największą dokładnością!*  \n",
    "__UWAGA__ : zabezpieczymy się przed losowością kilku pierwszych wartości __k__ (dokładnie to pierwszych pięciou) przy użyciu `if`!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bc0f9-02d8-4063-91f9-0a1cba984326",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_arr = [];\n",
    "\n",
    "for k = 1:train_rows_n   \n",
    "\n",
    "    all_guesses = 0;\n",
    "    correct_guesses = 0;\n",
    "\n",
    "    for test_row = 1:test_rows_n   \n",
    "        all_guesses = all_guesses + 1;\n",
    "\n",
    "        distances = [];\n",
    "\n",
    "        for j = 1:train_rows_n\n",
    "\n",
    "            distance = 0;\n",
    "            for i = 1:train_cols_n\n",
    "                distance = distance + abs(train_data(j, i) - test_data(test_row, i));\n",
    "            end\n",
    "\n",
    "            distances = [distances, distance];\n",
    "\n",
    "        end\n",
    "\n",
    "         d = sorted_dict(distances', train_labels, k);\n",
    "         predicted_label = most_frequent_value(d);\n",
    "\n",
    "         if predicted_label == test_labels(test_row, :)\n",
    "            correct_guesses = correct_guesses + 1;\n",
    "         end\n",
    "\n",
    "    end\n",
    "\n",
    "    accuracy = correct_guesses / all_guesses;\n",
    "    \n",
    "    if k <= 5\n",
    "        accuracy = 0;\n",
    "    end\n",
    "    \n",
    "    accuracy_arr = [accuracy_arr, accuracy];\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba2125-7b1e-47a7-b7f0-61e86ab6e191",
   "metadata": {},
   "source": [
    "*Algorytm napisany, poniżej wizualizacja podsumowująca wszystkie współczynniki __k__ wraz z ich dokładnościami:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026b2e7-74af-44f0-b97d-84265b1abb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1:train_rows_n;\n",
    "y = accuracy_arr;\n",
    "\n",
    "plot(x, y, 'b-');\n",
    "xlim([1 train_rows_n]);\n",
    "ylim([min(accuracy_arr(:, 6:end)) max(accuracy_arr)]);\n",
    "\n",
    "hold on;\n",
    "\n",
    "k = find(accuracy_arr == max(accuracy_arr), 1)\n",
    "k_acc = max(accuracy_arr)\n",
    "\n",
    "plot(k, k_acc, 'rsquare');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e3cf2-0816-4079-8343-03e0ecf6b07a",
   "metadata": {},
   "source": [
    "*W ten oto sposób napisaliśmy prosty algorytm __KNN__ od zera oraz przy okazji znaleźliśmy najbardziej optymalny współczynnik __k__ dla naszego datasetu.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aaed32-da3f-4d93-9851-43b5f54aa462",
   "metadata": {},
   "source": [
    "#### __Krok 7.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b5ec8-3c83-40eb-9827-675500b1d3e8",
   "metadata": {},
   "source": [
    "*Teraz należy tylko użyć algorytmu i spredykować klasy dla wierszy ze zmiennej `TestData`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e0d95-f696-4e2f-b6cb-06b1839ed3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = [];\n",
    "\n",
    "for test_row = 1:size(TestData, 1)  \n",
    "\n",
    "        distances = [];\n",
    "\n",
    "        for j = 1:train_rows_n\n",
    "\n",
    "            distance = 0;\n",
    "            for i = 1:train_cols_n\n",
    "                distance = distance + abs(train_data(j, i) - TestData(test_row, i));\n",
    "            end\n",
    "\n",
    "            distances = [distances, distance];\n",
    "\n",
    "        end\n",
    "\n",
    "         d = sorted_dict(distances', train_labels, k);\n",
    "         predicted_label = most_frequent_value(d);\n",
    "         \n",
    "         predicts = [predicts predicted_label];\n",
    "end\n",
    "\n",
    "\n",
    "ans = dictionary(1:size(TestData, 1), predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae442c-5fa6-45a1-a9db-8cd89ac61849",
   "metadata": {},
   "source": [
    "*Krzysztof Stawarz*  \n",
    "*Kraków, 14.03.2023*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.17.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
